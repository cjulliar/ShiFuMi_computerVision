{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test affichage classes + camera\n",
    "\n",
    "from typing import Any, List\n",
    "from ultralytics import YOLO\n",
    "from inference import InferencePipeline\n",
    "from inference.core.interfaces.stream.sinks import render_boxes\n",
    "from inference.core.interfaces.camera.entities import VideoFrame\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class VideoFrameWithPredictions:\n",
    "    def __init__(self, video_frame: VideoFrame, predictions: dict = None):\n",
    "        self.video_frame = video_frame\n",
    "        self.predictions = predictions or {}\n",
    "\n",
    "    @property\n",
    "    def image(self):\n",
    "        return self.video_frame.image\n",
    "\n",
    "    @property\n",
    "    def frame_id(self):\n",
    "        return self.video_frame.frame_id\n",
    "\n",
    "    @property\n",
    "    def frame_timestamp(self):\n",
    "        return self.video_frame.frame_timestamp\n",
    "\n",
    "class MyModel:\n",
    "\n",
    "    def __init__(self, weights_path: str):\n",
    "        # Load the YOLO model\n",
    "        self._model = YOLO(weights_path)\n",
    "        print(\"Modèle chargé avec succès\")\n",
    "\n",
    "    def infer(self, video_frames: List[VideoFrame]) -> List[VideoFrameWithPredictions]:\n",
    "        print('Video frames:', len(video_frames))\n",
    "        \n",
    "        # Convert the list of images to the format expected by YOLO\n",
    "        images = [v.image for v in video_frames]\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        images_np = [np.array(img) for img in images]\n",
    "\n",
    "        # Make predictions\n",
    "        results = self._model(images_np)\n",
    "\n",
    "        # Create a list to store enriched VideoFrames\n",
    "        enriched_video_frames = []\n",
    "\n",
    "        # Update video frames with predictions\n",
    "        for i, result in enumerate(results):\n",
    "            boxes = result.boxes.xyxy.tolist() if result.boxes else []\n",
    "            scores = result.boxes.conf.tolist() if result.boxes else []\n",
    "            class_indices = result.boxes.cls.tolist() if result.boxes else []\n",
    "\n",
    "            # Create a new VideoFrameWithPredictions\n",
    "            enriched_frame = VideoFrameWithPredictions(\n",
    "                video_frame=video_frames[i],\n",
    "                predictions={\n",
    "                    'boxes': boxes,\n",
    "                    'scores': scores,\n",
    "                    'class_indices': class_indices\n",
    "                }\n",
    "            )\n",
    "\n",
    "            enriched_video_frames.append(enriched_frame)\n",
    "\n",
    "        return enriched_video_frames\n",
    "\n",
    "def render_boxes_on_frame(video_frame_with_predictions: VideoFrameWithPredictions) -> VideoFrame:\n",
    "    # convertir l'image en numpy array\n",
    "    image = np.array(video_frame_with_predictions.image)\n",
    "    predictions = video_frame_with_predictions.predictions\n",
    "\n",
    "    if predictions:\n",
    "        boxes = predictions['boxes']\n",
    "        scores = predictions['scores']\n",
    "        class_indices = predictions['class_indices']\n",
    "\n",
    "        for box, score, class_idx in zip(boxes, scores, class_indices):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            label = f'Classe: {class_idx}, Probabilité: {score:.2f}'\n",
    "        \n",
    "            # dessiner le rectangle autour de l'objet détecté\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        \n",
    "            # mettre le label \n",
    "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    \n",
    "    video_frame_with_predictions.video_frame.image = image\n",
    "    return video_frame_with_predictions.video_frame\n",
    "\n",
    "my_model = MyModel(\"../models/shifumi_trained_yolo9c.pt\")\n",
    "pipeline = InferencePipeline.init_with_custom_logic(\n",
    "    on_video_frame=my_model.infer,\n",
    "    video_reference=0,  # Ensure this is the correct device ID for your webcam\n",
    "    on_prediction=render_boxes_on_frame,  # Function to run after each prediction\n",
    ")\n",
    "\n",
    "pipeline.start()\n",
    "pipeline.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from typing import Any, List\n",
    "from ultralytics import YOLO\n",
    "from inference import InferencePipeline\n",
    "from inference.core.interfaces.camera.entities import VideoFrame\n",
    "import numpy as np\n",
    "\n",
    "class MyModel:\n",
    "    def __init__(self, weights_path: str):\n",
    "        # Load the YOLO model\n",
    "        self._model = YOLO(weights_path)\n",
    "        print(\"Modèle chargé avec succès\")\n",
    "\n",
    "    def infer(self, video_frames: List[VideoFrame]) -> List[dict]:\n",
    "        print('Video frames:', len(video_frames))\n",
    "        \n",
    "        # Convert the list of images to the format expected by YOLO\n",
    "        images = [np.array(v.image) for v in video_frames]\n",
    "\n",
    "        # Make predictions\n",
    "        results = self._model(images)\n",
    "\n",
    "        # Create a list to store predictions for each frame\n",
    "        predictions = []\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.tolist() if result.boxes else []\n",
    "            scores = result.boxes.conf.tolist() if result.boxes else []\n",
    "            class_indices = result.boxes.cls.tolist() if result.boxes else []\n",
    "\n",
    "            prediction = {\n",
    "                'boxes': boxes,\n",
    "                'scores': scores,\n",
    "                'class_indices': class_indices\n",
    "            }\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "def render_boxes_on_frame(video_frame: VideoFrame, prediction: dict) -> VideoFrame:\n",
    "    # Convert the video frame to a numpy array\n",
    "    image = np.array(video_frame.image)\n",
    "\n",
    "    if prediction:\n",
    "        boxes = prediction['boxes']\n",
    "        scores = prediction['scores']\n",
    "        class_indices = prediction['class_indices']\n",
    "\n",
    "        for box, score, class_idx in zip(boxes, scores, class_indices):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            label = f'Classe: {class_idx}, Probabilité: {score:.2f}'\n",
    "        \n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        \n",
    "            # Put the label near the bounding box\n",
    "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the image with bounding boxes\n",
    "    cv2.imshow(\"Video Frame\", image)\n",
    "    cv2.waitKey(1)  # Add a small delay to allow the image to be rendered\n",
    "\n",
    "    # Update the video_frame with the new image containing the drawn boxes\n",
    "    video_frame.image = image\n",
    "    return video_frame\n",
    "\n",
    "my_model = MyModel(\"../models/shifumi_trained_yolo9c.pt\")\n",
    "\n",
    "def on_prediction(video_frames: List[VideoFrame], predictions: List[dict]) -> List[VideoFrame]:\n",
    "    enriched_frames = []\n",
    "    for video_frame, prediction in zip(video_frames, predictions):\n",
    "        enriched_frame = render_boxes_on_frame(video_frame, prediction)\n",
    "        enriched_frames.append(enriched_frame)\n",
    "    return enriched_frames\n",
    "\n",
    "pipeline = InferencePipeline.init_with_custom_logic(\n",
    "    on_video_frame=my_model.infer,\n",
    "    video_reference=0,  # Ensure this is the correct device ID for your webcam\n",
    "    on_prediction=on_prediction,  # Function to run after each prediction\n",
    ")\n",
    "\n",
    "pipeline.start()\n",
    "pipeline.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
